{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based in algorithm available at:https://www.pyimagesearch.com/2017/03/20/imagenet-vggnet-resnet-inception-xception-keras/\n",
    "\n",
    "An interesting implementation is also seen at https://gist.github.com/joelouismarino/a2ede9ab3928f999575423b9887abd14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications import InceptionV3\n",
    "from keras.applications import Xception # TensorFlow ONLY\n",
    "from keras.applications import VGG16\n",
    "from keras.applications import VGG19\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the argument parse and parse the arguments\n",
    "#ap = argparse.ArgumentParser()\n",
    "#ap.add_argument(\"-i\", \"--image\", required=True,\n",
    "#    help=\"path to the input image\")\n",
    "#ap.add_argument(\"-model\", \"--model\", type=str, default=\"vgg16\",\n",
    "#    help=\"name of pre-trained network to use\")\n",
    "#args = vars(ap.parse_args())\n",
    "args = {\"model\":\"inception\",\n",
    "        \"image0\":\"images/soccer_ball.jpg\",\n",
    "        \"image1\":\"images/flower01.jpg\",\n",
    "        \"image2\":\"images/flower02.jpg\",}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dictionary that maps model names to their classes\n",
    "# inside Keras\n",
    "MODELS = {\n",
    "    \"vgg16\": VGG16,\n",
    "    \"vgg19\": VGG19,\n",
    "    \"inception\": InceptionV3,\n",
    "    \"xception\": Xception, # TensorFlow ONLY\n",
    "    \"resnet\": ResNet50\n",
    "}\n",
    " \n",
    "# esnure a valid model name was supplied via command line argument\n",
    "if args[\"model\"] not in MODELS.keys():\n",
    "    raise AssertionError(\"The --model command line argument should \"\n",
    "        \"be a key in the `MODELS` dictionary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the input image shape (224x224 pixels) along with\n",
    "# the pre-processing function (this might need to be changed\n",
    "# based on which model we use to classify our image)\n",
    "inputShape = (224, 224)\n",
    "preprocess = imagenet_utils.preprocess_input\n",
    " \n",
    "# if we are using the InceptionV3 or Xception networks, then we\n",
    "# need to set the input shape to (299x299) [rather than (224x224)]\n",
    "# and use a different image processing function\n",
    "if args[\"model\"] in (\"inception\", \"xception\"):\n",
    "    inputShape = (299, 299)\n",
    "    preprocess = preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading inception...\n"
     ]
    }
   ],
   "source": [
    "# load our the network weights from disk (NOTE: if this is the\n",
    "# first time you are running this script for a given network, the\n",
    "# weights will need to be downloaded first -- depending on which\n",
    "# network you are using, the weights can be 90-575MB, so be\n",
    "# patient; the weights will be cached and subsequent runs of this\n",
    "# script will be *much* faster)\n",
    "print(\"[INFO] loading {}...\".format(args[\"model\"]))\n",
    "Network = MODELS[args[\"model\"]]\n",
    "model = Network(weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying flower images with the traditional InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating functions to classify the images and analyse the 5 top categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(image_path,input_shape):\n",
    "    # load the input image using the Keras helper utility while ensuring\n",
    "    # the image is resized to `inputShape`, the required input dimensions\n",
    "    # for the ImageNet pre-trained network\n",
    "    #print(\"[INFO] loading and pre-processing image...\")\n",
    "    image = load_img(image_path, target_size=input_shape)\n",
    "    image = img_to_array(image)\n",
    "    \n",
    "    # our input image is now represented as a NumPy array of shape\n",
    "    # (inputShape[0], inputShape[1], 3) however we need to expand the\n",
    "    # dimension by making the shape (1, inputShape[0], inputShape[1], 3)\n",
    "    # so we can pass it through thenetwork\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    \n",
    "    # pre-process the image using the appropriate function based on the\n",
    "    # model that has been loaded (i.e., mean subtraction, scaling, etc.)\n",
    "    image = preprocess(image)\n",
    "    \n",
    "    # classify the image\n",
    "    #print(\"[INFO] classifying image with '{}'...\".format(args[\"model\"]))\n",
    "    preds = model.predict(image)\n",
    "    #P = imagenet_utils.decode_predictions(preds)\n",
    "    \n",
    "    return preds\n",
    "\n",
    "def get_files_names(mypath):\n",
    "    from os import listdir\n",
    "    from os.path import isfile, join\n",
    "    onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "    return onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n"
     ]
    }
   ],
   "source": [
    "images_path = '/home/vfinotti/Pictures/output/short/'\n",
    "images_list = get_files_names(images_path)\n",
    "\n",
    "\n",
    "categories_count = np.zeros([1,1000])\n",
    "\n",
    "for idx, image in enumerate(images_list):\n",
    "    if (idx%10 == 0):\n",
    "        print(idx)\n",
    "    preds = classify_image(images_path+image, inputShape)\n",
    "    #max_value = max(preds)\n",
    "    #max_index = preds.index(max_value)\n",
    "    max_index = np.argmax(preds,axis=1)\n",
    "    \n",
    "    categories_count[0, max_index] = categories_count[0, max_index] + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. pot: 36.0 times\n",
      "2. daisy: 33.0 times\n",
      "3. ant: 17.0 times\n",
      "4. bee: 14.0 times\n",
      "5. yellow_lady's_slipper: 13.0 times\n",
      "6. picket_fence: 11.0 times\n",
      "7. hip: 9.0 times\n",
      "8. earthstar: 8.0 times\n",
      "9. cabbage_butterfly: 8.0 times\n",
      "10. buckeye: 7.0 times\n",
      "11. zucchini: 6.0 times\n",
      "12. hen-of-the-woods: 6.0 times\n",
      "13. mushroom: 6.0 times\n",
      "14. rapeseed: 5.0 times\n",
      "15. strawberry: 4.0 times\n"
     ]
    }
   ],
   "source": [
    "P = imagenet_utils.decode_predictions(categories_count, top=15)\n",
    "for (i, (imagenetID, label, prob)) in enumerate(P[0]):\n",
    "    print(\"{}. {}: {} times\".format(i + 1, label, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "images_path = '/home/vfinotti/Pictures/output/full/'\n",
    "images_list = get_files_names(images_path)\n",
    "\n",
    "\n",
    "categories_count = np.zeros([1,1000])\n",
    "\n",
    "for idx, image in enumerate(images_list):\n",
    "    if (idx%100 == 0):\n",
    "        print(idx)\n",
    "    preds = classify_image(images_path+image, inputShape)\n",
    "    #max_value = max(preds)\n",
    "    #max_index = preds.index(max_value)\n",
    "    max_index = np.argmax(preds,axis=1)\n",
    "    \n",
    "    categories_count[0, max_index] = categories_count[0, max_index] + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. pot: 856.0 times\n",
      "2. daisy: 427.0 times\n",
      "3. bee: 282.0 times\n",
      "4. picket_fence: 208.0 times\n",
      "5. yellow_lady's_slipper: 196.0 times\n",
      "6. ant: 170.0 times\n",
      "7. buckeye: 144.0 times\n",
      "8. hip: 138.0 times\n",
      "9. earthstar: 116.0 times\n",
      "10. hen-of-the-woods: 111.0 times\n",
      "11. rapeseed: 94.0 times\n",
      "12. cabbage_butterfly: 89.0 times\n",
      "13. pinwheel: 85.0 times\n",
      "14. zucchini: 81.0 times\n",
      "15. mushroom: 69.0 times\n"
     ]
    }
   ],
   "source": [
    "P = imagenet_utils.decode_predictions(categories_count, top=15)\n",
    "for (i, (imagenetID, label, prob)) in enumerate(P[0]):\n",
    "    print(\"{}. {}: {} times\".format(i + 1, label, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading and pre-processing image...\n",
      "[INFO] classifying image with 'inception'...\n",
      "1. soccer_ball: 100.00%\n",
      "2. volleyball: 0.00%\n",
      "3. silky_terrier: 0.00%\n",
      "4. sea_urchin: 0.00%\n",
      "5. screw: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# load the input image using the Keras helper utility while ensuring\n",
    "# the image is resized to `inputShape`, the required input dimensions\n",
    "# for the ImageNet pre-trained network\n",
    "print(\"[INFO] loading and pre-processing image...\")\n",
    "image = load_img(args[\"image0\"], target_size=inputShape)\n",
    "image = img_to_array(image)\n",
    " \n",
    "# our input image is now represented as a NumPy array of shape\n",
    "# (inputShape[0], inputShape[1], 3) however we need to expand the\n",
    "# dimension by making the shape (1, inputShape[0], inputShape[1], 3)\n",
    "# so we can pass it through thenetwork\n",
    "image = np.expand_dims(image, axis=0)\n",
    " \n",
    "# pre-process the image using the appropriate function based on the\n",
    "# model that has been loaded (i.e., mean subtraction, scaling, etc.)\n",
    "image = preprocess(image)\n",
    "\n",
    "\n",
    "# classify the image\n",
    "print(\"[INFO] classifying image with '{}'...\".format(args[\"model\"]))\n",
    "preds = model.predict(image)\n",
    "P = imagenet_utils.decode_predictions(preds)\n",
    " \n",
    "# loop over the predictions and display the rank-5 predictions +\n",
    "# probabilities to our terminal\n",
    "for (i, (imagenetID, label, prob)) in enumerate(P[0]):\n",
    "    print(\"{}. {}: {:.2f}%\".format(i + 1, label, prob * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('n04254680', 'soccer_ball', 0.9999795), ('n04540053', 'volleyball', 1.2911725e-06), ('n02097658', 'silky_terrier', 9.2055751e-07), ('n02319095', 'sea_urchin', 5.1510028e-07), ('n04153751', 'screw', 4.2401675e-07)]]\n"
     ]
    }
   ],
   "source": [
    "print(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading and pre-processing image...\n",
      "[INFO] classifying image with 'inception'...\n",
      "1. picket_fence: 66.42%\n",
      "2. pot: 4.95%\n",
      "3. bee: 3.19%\n",
      "4. cabbage_butterfly: 2.64%\n",
      "5. vase: 2.03%\n"
     ]
    }
   ],
   "source": [
    "# load the input image using the Keras helper utility while ensuring\n",
    "# the image is resized to `inputShape`, the required input dimensions\n",
    "# for the ImageNet pre-trained network\n",
    "print(\"[INFO] loading and pre-processing image...\")\n",
    "image = load_img(args[\"image1\"], target_size=inputShape)\n",
    "image = img_to_array(image)\n",
    " \n",
    "# our input image is now represented as a NumPy array of shape\n",
    "# (inputShape[0], inputShape[1], 3) however we need to expand the\n",
    "# dimension by making the shape (1, inputShape[0], inputShape[1], 3)\n",
    "# so we can pass it through thenetwork\n",
    "image = np.expand_dims(image, axis=0)\n",
    " \n",
    "# pre-process the image using the appropriate function based on the\n",
    "# model that has been loaded (i.e., mean subtraction, scaling, etc.)\n",
    "image = preprocess(image)\n",
    "\n",
    "\n",
    "# classify the image\n",
    "print(\"[INFO] classifying image with '{}'...\".format(args[\"model\"]))\n",
    "preds = model.predict(image)\n",
    "P = imagenet_utils.decode_predictions(preds)\n",
    " \n",
    "# loop over the predictions and display the rank-5 predictions +\n",
    "# probabilities to our terminal\n",
    "for (i, (imagenetID, label, prob)) in enumerate(P[0]):\n",
    "    print(\"{}. {}: {:.2f}%\".format(i + 1, label, prob * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading and pre-processing image...\n",
      "[INFO] classifying image with 'inception'...\n",
      "1. cabbage_butterfly: 34.30%\n",
      "2. bee: 8.07%\n",
      "3. monarch: 6.79%\n",
      "4. cardoon: 5.13%\n",
      "5. pot: 4.40%\n"
     ]
    }
   ],
   "source": [
    "# load the input image using the Keras helper utility while ensuring\n",
    "# the image is resized to `inputShape`, the required input dimensions\n",
    "# for the ImageNet pre-trained network\n",
    "print(\"[INFO] loading and pre-processing image...\")\n",
    "image = load_img(args[\"image2\"], target_size=inputShape)\n",
    "image = img_to_array(image)\n",
    " \n",
    "# our input image is now represented as a NumPy array of shape\n",
    "# (inputShape[0], inputShape[1], 3) however we need to expand the\n",
    "# dimension by making the shape (1, inputShape[0], inputShape[1], 3)\n",
    "# so we can pass it through thenetwork\n",
    "image = np.expand_dims(image, axis=0)\n",
    " \n",
    "# pre-process the image using the appropriate function based on the\n",
    "# model that has been loaded (i.e., mean subtraction, scaling, etc.)\n",
    "image = preprocess(image)\n",
    "\n",
    "\n",
    "# classify the image\n",
    "print(\"[INFO] classifying image with '{}'...\".format(args[\"model\"]))\n",
    "preds = model.predict(image)\n",
    "P = imagenet_utils.decode_predictions(preds)\n",
    " \n",
    "# loop over the predictions and display the rank-5 predictions +\n",
    "# probabilities to our terminal\n",
    "for (i, (imagenetID, label, prob)) in enumerate(P[0]):\n",
    "    print(\"{}. {}: {:.2f}%\".format(i + 1, label, prob * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image via OpenCV, draw the top prediction on the image,\n",
    "# and display the image to our screen\n",
    "#orig = cv2.imread(args[\"image\"])\n",
    "#(imagenetID, label, prob) = P[0][0]\n",
    "#cv2.putText(orig, \"Label: {}, {:.2f}%\".format(label, prob * 100),\n",
    "#    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "#cv2.imshow(\"Classification\", orig)\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying flower images with the finetuned InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"se...)`\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "\n",
    "# build the inception network\n",
    "base_model = InceptionV3(weights=None, include_top=False,\n",
    "                         input_shape = (150, 150, 3))\n",
    "print('Model loaded.')\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "#model.add(top_model)\n",
    "model = Model(input= base_model.input, output= top_model(base_model.output))\n",
    "\n",
    "model.load_weights('./weights/inceptionv3_finetuned.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = '/home/vfinotti/Pictures/output/full/'\n",
    "images_list = get_files_names(images_path)\n",
    "\n",
    "\n",
    "categories_count = np.zeros([1,1000])\n",
    "\n",
    "for idx, image in enumerate(images_list):\n",
    "#    if (idx%100 == 0):\n",
    "#        print(idx)\n",
    "    preds = classify_image(images_path+image, inputShape)\n",
    "    #max_value = max(preds)\n",
    "    #max_index = preds.index(max_value)\n",
    "    max_index = np.argmax(preds,axis=1)\n",
    "    categories_count[0, max_index] = categories_count[0, max_index] + 1 \n",
    "    \n",
    "#P = imagenet_utils.decode_predictions(categories_count, top=15)\n",
    "#for (i, (imagenetID, label, prob)) in enumerate(P[0]):\n",
    "#    print(\"{}. {}: {} times\".format(i + 1, label, prob))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
